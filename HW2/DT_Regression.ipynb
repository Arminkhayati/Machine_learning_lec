{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "civilian-warning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from copy import deepcopy\n",
    "from scipy.stats import mode\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# data = pd.read_csv('2.txt',sep='\\t',names=list(range(5)))\n",
    "\n",
    "\n",
    "def two_attribute_std(data, feature):\n",
    "    uniques = np.unique(data[:,feature])\n",
    "    total_size = data.shape[0]\n",
    "    std = 0\n",
    "    for v in uniques:\n",
    "        X = data[data[:,feature] == v]\n",
    "        size = X.shape[0]\n",
    "        v_std = X[:, -1].std()\n",
    "        p = size / total_size\n",
    "        std = std + (p * v_std)\n",
    "    return std    \n",
    "        \n",
    "        \n",
    "def sdr_calc(data, feature):\n",
    "    std = data[:, -1].std()\n",
    "    std2 = two_attribute_std(data, feature)\n",
    "    return std - std2\n",
    "\n",
    "def calc_cv(data):\n",
    "    std = data[:, -1].std()\n",
    "    mean = data[:, -1].mean()\n",
    "    return (std / mean) * 100\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, data, parent=None, f_index = None, f_value = None, threshold = 10, count = 3):\n",
    "        self.data = data\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.f_index = f_index\n",
    "        self.f_value = f_value\n",
    "        self.count = count\n",
    "        self.threshold = threshold\n",
    "        self.value = None\n",
    "        self.leaf = self.isleaf()\n",
    "    \n",
    "    def isleaf(self):\n",
    "        if self.data.ndim == 1: # Out of feature\n",
    "            self.value = self.data.mean()\n",
    "            return True\n",
    "        elif self.data.shape[1] <= 1:\n",
    "            self.value = self.data.mean()\n",
    "            return True\n",
    "        elif self.data.shape[0] <= self.count: # Count of remaining data is equal or less than smth\n",
    "            self.value = self.data[:,-1].mean()\n",
    "            return True\n",
    "        elif calc_cv(self.data) <= self.threshold: # CV is equal or less than threshold\n",
    "            self.value = self.data[:,-1].mean()\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def add_children(self, node):\n",
    "        self.children.append(node)\n",
    "        \n",
    "    def get_best_feature_to_split(self):\n",
    "        best_f_index = 0\n",
    "        best_sdr = 0\n",
    "        for f in range(0, self.data.shape[1] - 1):\n",
    "            sdr = sdr_calc(self.data, f)\n",
    "            if sdr > best_sdr:\n",
    "                best_sdr = sdr\n",
    "                best_f_index = f\n",
    "        return best_f_index\n",
    "    \n",
    "    def visited(self):\n",
    "        if self.children: # Has children. It's not empty\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    \n",
    "class DTRegression:\n",
    "    def __init__(self, data, count=3, threshold=10):\n",
    "        self.count = count\n",
    "        self.threshold = threshold\n",
    "        self.root = Node(data, count=self.count, threshold= self.threshold)\n",
    "        self.unvisited_nodes = [self.root]\n",
    "        self.visited_nodes = []\n",
    "\n",
    "    \n",
    "    def fit(self):\n",
    "        while self.unvisited_nodes: # While list is not Empty\n",
    "            \n",
    "            n = self.unvisited_nodes.pop(0)\n",
    "            best_feature = n.get_best_feature_to_split()\n",
    "            self.visited_nodes.append(n)\n",
    "            n.f_index = best_feature\n",
    "            self.split_and_make_children(n, best_feature)\n",
    "            \n",
    "    \n",
    "    def split_and_make_children(self, node, f_index):\n",
    "        data = node.data\n",
    "        unique_values = np.unique(data[:, f_index])\n",
    "        for v in unique_values:\n",
    "            new_data = data[data[:,f_index] == v]\n",
    "            new_data = np.delete(new_data, f_index, axis=1)     \n",
    "            n = Node(new_data, parent=node, f_index=None, f_value=v, count=self.count, threshold= self.threshold)\n",
    "            node.add_children(n)\n",
    "            \n",
    "            if n.leaf :\n",
    "                self.visited_nodes.append(n)\n",
    "            else:\n",
    "                self.unvisited_nodes.append(n)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        result = []\n",
    "        for i, x in enumerate(X):\n",
    "            result.append(self._predict(x))\n",
    "        return result    \n",
    "    \n",
    "    def _predict(self, x):\n",
    "        current_node = self.root\n",
    "        while True:\n",
    "            if current_node.leaf:\n",
    "                return current_node.value\n",
    "            for ch in current_node.children:\n",
    "                found = False\n",
    "                if ch.f_value == x[current_node.f_index]:\n",
    "                    found = True\n",
    "                    x = np.delete(x, current_node.f_index)  \n",
    "                    current_node = ch   \n",
    "                    break\n",
    "#             if not found:\n",
    "#                 return current_node.data[:,-1].mean()\n",
    "        return current_node.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-playlist",
   "metadata": {},
   "source": [
    "# EnjoySport Dataset Regression From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "noted-rehabilitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enjoy sport MSE:  14.208333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "data = pd.read_csv('2.txt',sep='\\t',names=list(range(5))).to_numpy()\n",
    "dtr = DTRegression(data, count=3)\n",
    "dtr.fit()\n",
    "preds = dtr.predict(data)\n",
    "print('Enjoy sport MSE: ', mean_squared_error(data[:,-1], preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-routine",
   "metadata": {},
   "source": [
    "# Automobil Dataset Regression From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "choice-contamination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(657, 12)\n",
      "2733208.48681576\n",
      "8465942.878553528 ,  8363341\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv('31.txt',sep='\\t',names=list(range(12))).to_numpy()\n",
    "\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.3 )\n",
    "print(test.shape)\n",
    "dtr = DTRegression(train, count=5, threshold=1)\n",
    "dtr.fit()\n",
    "preds = dtr.predict(test)\n",
    "print(mean_squared_error(test[:,-1], preds))\n",
    "dif = pd.DataFrame({'pred': preds, 'real':test[:,-1]})\n",
    "print(dif['pred'].sum(), ', ', dif['real'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "funky-uzbekistan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average + STD =  2781598.6418455904  ±  325501.93123312865\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for _ in range(10):\n",
    "    train, test = train_test_split(data, test_size=0.3)\n",
    "    dtr = DTRegression(train, count=8)\n",
    "    dtr.fit()\n",
    "    preds = dtr.predict(test)\n",
    "    results.append(mean_squared_error(test[:,-1], preds))\n",
    "print('Average + STD = ', np.mean(results), ' ± ', np.std(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-terminal",
   "metadata": {},
   "source": [
    "# Automobil Dataset Regression With DecisionTreeRegressor from Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "protected-reading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39119908.91157408\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "data = pd.read_csv('3.txt',sep='\\t',names=list(range(12))).to_numpy()\n",
    "enc = OrdinalEncoder()\n",
    "enc.fit(data[:, :-1])\n",
    "d = enc.transform(data[:, :-1])\n",
    "data = np.insert(d, 11 ,data[:,-1], axis=1)\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.3 )\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor(random_state=0)\n",
    "regressor.fit(train[:,:-1], train[:, -1])\n",
    "preds = regressor.predict(test[:,:-1])\n",
    "print(mean_squared_error(test[:,-1], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "administrative-transmission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average + STD =  18002941.053611107  ±  8366768.374052806\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for _ in range(10):\n",
    "    train, test = train_test_split(data, test_size=0.3)\n",
    "    regressor = DecisionTreeRegressor()\n",
    "    regressor.fit(train[:,:-1], train[:, -1])\n",
    "    preds = regressor.predict(test[:,:-1])\n",
    "    results.append(mean_squared_error(test[:,-1], preds))\n",
    "print('Average + STD = ', np.mean(results), ' ± ', np.std(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-earthquake",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
